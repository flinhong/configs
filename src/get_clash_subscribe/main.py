import os
import re
import time
from datetime import datetime

import requests
import yaml

requests.packages.urllib3.disable_warnings()


ok_code = [200, 201, 202, 203, 204, 205, 206]


def write_log(content, level="INFO"):

    date_str = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))
    update_log = f"[{date_str}] [{level}] {content}\n"
    print(update_log)
    with open(f'./public/subscribe/log/{time.strftime("%Y-%m", time.localtime(time.time()))}-update.log', 'a', encoding="utf-8") as f:
        f.write(update_log)

def get_subscribe_main():
    dirs = './public/subscribe'
    if not os.path.exists(dirs):
        os.makedirs(dirs)
    log_dir = "./public/subscribe/log"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)

    clash_req = requests.get("https://git.io/emzclash")

    # æ£€æŸ¥ä¸‹è½½æ˜¯å¦æˆåŠŸ
    if not clash_req.status_code in ok_code:
        write_log("æ›´æ–°å¤±è´¥ï¼æ— æ³•æ‹‰å– emzclash è®¢é˜…å†…å®¹", "WARN")
        return None
    
    try:
        clash_content = check_and_validate_file("https://git.io/emzclash")
        clash_content_replaced = re.sub(r"https://raw.githubusercontent.com", "https://cdn.honglin.ac.cn/statically/gh", clash_content, flags=re.IGNORECASE)
        # clash_content_replaced = re.sub(r"http://www.gstatic.com/generate_204", "https://www.gstatic.com/generate_204", clash_content_replaced, flags=re.IGNORECASE)
        # clash_content_replaced = re.sub(r"tolerance: 50", "tolerance: 10", clash_content_replaced, flags=re.IGNORECASE)

        # å°†æ›´æ–°åçš„å†…å®¹å†™å…¥æ–‡ä»¶
        with open(dirs + '/clash.yml', 'w', encoding="utf-8") as f:
            f.write(clash_content_replaced)
            write_log(f"åŒæ­¥è®¢é˜…æˆåŠŸ", "INFO")

        extra_proxies = download_extra_proxies()
        if extra_proxies is not None:
            clash_yaml = yaml.safe_load(clash_content_replaced)
            clash_content_updated = append_proxies(clash_yaml, extra_proxies)
            # å°†åˆå¹¶åçš„å†…å®¹å†™å…¥æ–‡ä»¶
            with open(dirs + '/clash.yml', 'w', encoding="utf-8") as f:
                f.write(clash_content_updated)
                write_log(f"åˆå¹¶è®¢é˜…æˆåŠŸ", "INFO")
        else:
            return
    except Exception as e:
        write_log(f"è®¢é˜…è§£æé”™è¯¯", "WARN")
        return None
    
def expand_auto_proxies():
    dirs = './public/subscribe'
    if not os.path.exists(dirs):
        os.makedirs(dirs)

    clash_path = dirs + '/clash.yml'
    tmp_path = './src/get_clash_subscribe/tmp.yaml'

    try:
        with open(clash_path, 'r', encoding='utf8') as file:
            clash_data = yaml.safe_load(file)
        with open(tmp_path, 'r', encoding='utf8') as file:
            extend_data = yaml.safe_load(file)

        clash_data_proxies = clash_data.get('proxies', [])
        extend_data_proxies = extend_data.get('proxies', [])
        

        clash_data_proxies.extend(extend_data_proxies)

        # æ›´æ–° proxy åˆ—è¡¨
        clash_data['proxies'] = clash_data_proxies

        # åœ¨[â™»ï¸ è‡ªåŠ¨é€‰æ‹©]åˆ—è¡¨ä¸­å¢åŠ èŠ‚ç‚¹åå­—
        clash_data_groups = clash_data.get('proxy-groups', [])
        for group in clash_data_groups:
            if group.get('name') == 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©':
                  original_auto_proxies = group.get('proxies', [])
                  original_auto_proxies.extend([item['name'] for item in extend_data_proxies])
                  group['proxies'] = original_auto_proxies

        # å†å†™å…¥æ–‡ä»¶
        with open(clash_path, 'w', encoding="utf-8") as f:
            f.write(yaml.dump(clash_data, default_flow_style=False, allow_unicode=True, sort_keys=False))
            write_log(f"è‡ªå®šä¹‰èŠ‚ç‚¹å†™å…¥æˆåŠŸ", "INFO") 
        
    except Exception as e:
        print(f"ä¿®æ”¹æ–‡ä»¶å‘ç”Ÿé”™è¯¯: {e}")
    
def append_proxies(clash_yaml, proxies):
    # å°†æ–°çš„èŠ‚ç‚¹åˆ—è¡¨è¿½åŠ åˆ°åŸè®¢é˜…çš„èŠ‚ç‚¹åˆ—è¡¨
    original_proxies = clash_yaml.get('proxies', [])
    # å°†åŸè®¢é˜…çš„èŠ‚ç‚¹åˆ—è¡¨ä¸ node_free_proxies åˆå¹¶
    original_proxies.extend(proxies)
    # æ›´æ–°åŸè®¢é˜…çš„èŠ‚ç‚¹åˆ—è¡¨
    clash_yaml['proxies'] = original_proxies

    # # æ›´æ–°[â™»ï¸ è‡ªåŠ¨é€‰æ‹©]åˆ—è¡¨
    # original_groups = clash_yaml.get('proxy-groups', [])
    # for group in original_groups:
    #     if group.get('name') == 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©':
    #         # è·å–åŸè®¢é˜…çš„èŠ‚ç‚¹åˆ—è¡¨
    #         original_auto_proxies = group.get('proxies', [])
    #         # å°†åŸè®¢é˜…çš„èŠ‚ç‚¹åˆ—è¡¨ä¸é¢å¤–èŠ‚ç‚¹åˆå¹¶
    #         extra_proxy_names = [item['name'] for item in proxies]
    #         original_auto_proxies.extend(extra_proxy_names)
    #         # æ›´æ–°åŸè®¢é˜…çš„èŠ‚ç‚¹åˆ—è¡¨
    #         group['proxies'] = original_auto_proxies
    # # å°†æ›´æ–°åçš„å†…å®¹å†™å›åˆ°YAMLæ–‡ä»¶
    # clash_yaml_replaced = yaml.dump(clash_yaml, default_flow_style=False, allow_unicode=True)
    # return clash_yaml_replaced

    # è¿½åŠ [ğŸª è´Ÿè½½å‡è¡¡]åˆ—è¡¨
    original_groups = clash_yaml.get('proxy-groups', [])
    original_groups.append({
        'name': "ğŸª è´Ÿè½½å‡è¡¡",
        'type': "load-balance",
        'url': "https://client3.google.com/generate_204",
        'interval': 120,
        'strategy': "consistent-hashing",
        'proxies': [item['name'] for item in proxies]
    })
    
    # ä¿®æ”¹åŸ[â™»ï¸ è‡ªåŠ¨é€‰æ‹©]åˆ—è¡¨
    for group in original_groups:
        if group.get('name') == 'â™»ï¸ è‡ªåŠ¨é€‰æ‹©':
            # è·å–åŸè®¢é˜…çš„èŠ‚ç‚¹åˆ—è¡¨
            original_auto_proxies = group.get('proxies', [])
            # å°†è´Ÿè½½å‡è¡¡æ·»åŠ åˆ°è‡ªåŠ¨é€‰æ‹©
            original_auto_proxies.insert(0, "ğŸª è´Ÿè½½å‡è¡¡")
            # æ›´æ–°åŸè®¢é˜…çš„èŠ‚ç‚¹åˆ—è¡¨
            group['proxies'] = original_auto_proxies
            group['url'] = "https://www.facebook.com/common/referer_frame.php"
            group['interval'] = 60
            group['tolerance'] = 1

    clash_yaml_replaced = yaml.dump(clash_yaml, default_flow_style=False, allow_unicode=True, sort_keys=False)
    return clash_yaml_replaced

def validate_yaml(data):
    try:
        yaml.safe_load(data)
        return True
    except yaml.YAMLError as exc:
        print(f"Error validating YAML: {e}")
        return False

def check_and_validate_file(url):
    response = requests.get(url)
    print(f"è·å– {url} çŠ¶æ€ç : {response.status_code}")
    if not response.status_code in ok_code:
        return None
    
    try:
        data = response.content.decode('utf-8')
        if validate_yaml(data):
            return data
        else:
            return None
    except Exception as e:
        print(e)
        return None

def download_extra_proxies():
    current_date = datetime.now()
    current_date_str = (current_date).strftime('%Y/%m/%Y%m%d')
    current_date_str_short = (current_date).strftime('%Y%m%d')

    urls = [
        "https://raw.githubusercontent.com/zhangkaiitugithub/passcro/main/speednodes.yaml",
        # "https://raw.githubusercontent.com/NiREvil/vless/main/sub/clash-meta-wg.yml",
        # "https://raw.githubusercontent.com/ts-sf/fly/main/clash",
        # "https://raw.githubusercontent.com/MrMohebi/xray-proxy-grabber-telegram/master/collected-proxies/clash-meta/actives_under_1000ms.yaml",
        # "https://raw.githubusercontent.com/mahdibland/V2RayAggregator/master/sub/sub_merge_yaml.yml",
        f"https://free.datiya.com/uploads/{current_date_str_short}-clash.yaml",
        f"https://v2rayshare.githubrowcontent.com/{current_date_str}.yaml",
        f"https://nodefree.githubrowcontent.com/{current_date_str}.yaml"
    ]
    all_proxies = []

    for file_url in urls:
        try:
            data = check_and_validate_file(file_url)
            if data is not None:
                proxies = get_extra_proxies(data)
                all_proxies.extend(proxies)
            
        except Exception as e:
            print(f"Error downloading or processing {file_url}: {e}")

    unique_proxies = remove_duplicate_proxies(all_proxies)
    return unique_proxies

def remove_duplicate_proxies(proxies):
    seen_servers = set()
    unique_proxies = []
    for proxy in proxies:
        server = proxy.get('server')
        if server and server not in seen_servers:
            unique_proxies.append(proxy)
            seen_servers.add(server)
    return unique_proxies

def get_extra_proxies(data):
    yaml_data = yaml.safe_load(data)
    proxies = yaml_data.get('proxies', [])
    filter_string = ['æœªçŸ¥', 'tg', 'TG', 'KB/s']
    filtered_proxies = [proxy for proxy in proxies if not any(str in proxy['name'] for str in filter_string)]
    # filtered_proxies = [proxy for proxy in filtered_proxies if not proxy['type']=='ss' ]

    # é˜²æ­¢åç§°å’Œ ermz é‡å¤
    for proxy in filtered_proxies:
        if 'name' in proxy and proxy['name']:
            proxy['name'] = f"X_{proxy['name']}"
        else:
            print("No name found in the proxy")
            return None

    return filtered_proxies

def main():
    get_subscribe_main()
    expand_auto_proxies()


# ä¸»å‡½æ•°å…¥å£
if __name__ == '__main__':
    main()
